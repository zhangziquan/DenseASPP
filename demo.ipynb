{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "\n",
    "SAVE_PATH = \"./results/\"\n",
    "\n",
    "\n",
    "IS_MULTISCALE = True\n",
    "N_CLASS = 19\n",
    "COLOR_MAP = [(128, 64, 128), (244, 35, 232), (70, 70, 70), (102, 102, 156), (190, 153, 153), (153, 153, 153),\n",
    "             (250, 170, 30), (220, 220, 0), (107, 142, 35), (152, 251, 152), (70, 130, 180), (220, 20, 60),\n",
    "             (255,  0,  0), (0, 0, 142), (0, 0, 70), (0, 60, 100), (0, 80, 100), (0, 0, 230), (119, 11, 32)]\n",
    "\n",
    "inf_scales = [0.5, 0.75, 1.0, 1.25, 1.5, 1.8]\n",
    "data_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.290101, 0.328081, 0.286964],\n",
    "                                                           [0.182954, 0.186566, 0.184475])])\n",
    "\n",
    "\n",
    "class Inference(object):\n",
    "\n",
    "    def __init__(self, model_name, model_path):\n",
    "        print(model_name,model_path)\n",
    "\n",
    "        self.seg_model = self.__init_model(model_name, model_path, is_local=False)\n",
    "\n",
    "    def __init_model(self, model_name, model_path, is_local=False):\n",
    "        if model_name == 'MobileNetDenseASPP':\n",
    "            from cfgs.MobileNetDenseASPP import Model_CFG\n",
    "            from models.MobileNetDenseASPP import DenseASPP\n",
    "        elif model_name == 'DenseASPP121':\n",
    "            from cfgs.DenseASPP121 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "        elif model_name == 'DenseASPP169':\n",
    "            from cfgs.DenseASPP169 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "        elif model_name == 'DenseASPP201':\n",
    "            from cfgs.DenseASPP201 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "        elif model_name == 'DenseASPP161':\n",
    "            from cfgs.DenseASPP161 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "        else:\n",
    "            from cfgs.DenseASPP161 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "\n",
    "        seg_model = DenseASPP(Model_CFG, n_class=N_CLASS, output_stride=8)\n",
    "        #self.__load_weight(seg_model, model_path, is_local=is_local)\n",
    "        seg_model.train()\n",
    "        seg_model = seg_model.cuda()\n",
    "\n",
    "        return seg_model\n",
    "\n",
    "    def folder_inference(self, img_dir, is_multiscale=True):\n",
    "        folders = sorted(os.listdir(img_dir))\n",
    "        for f in folders:\n",
    "            save_path = SAVE_PATH + f + \"/\"\n",
    "            read_path = os.path.join(img_dir, f)\n",
    "            names = sorted(os.listdir(read_path))\n",
    "            for n in names:\n",
    "                if not n.endswith(\".png\"):\n",
    "                    continue\n",
    "                print(n)\n",
    "                read_name = os.path.join(read_path, n)\n",
    "                img = Image.open(read_name)\n",
    "                if is_multiscale:\n",
    "                    pre = self.multiscale_inference(img)\n",
    "                else:\n",
    "                    pre = self.single_inference(img)\n",
    "                mask = self.pre_to_img(pre)\n",
    "                cv2.imwrite(save_path + n, mask)\n",
    "                print(save_path + n)\n",
    "                #cv2.imshow('DenseASPP', mask)\n",
    "                #cv2.waitKey(0)\n",
    "\n",
    "    def multiscale_inference(self, test_img):\n",
    "        h, w = test_img.size\n",
    "        pre = []\n",
    "        for scale in inf_scales:\n",
    "            img_scaled = test_img.resize((int(h * scale), int(w * scale)), Image.CUBIC)\n",
    "            pre_scaled = self.single_inference(img_scaled, is_flip=False)\n",
    "            pre.append(pre_scaled)\n",
    "\n",
    "            img_scaled = img_scaled.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            pre_scaled = self.single_inference(img_scaled, is_flip=True)\n",
    "            pre.append(pre_scaled)\n",
    "\n",
    "        pre_final = self.__fushion_avg(pre)\n",
    "\n",
    "        return pre_final\n",
    "\n",
    "    def single_inference(self, test_img, is_flip=False):\n",
    "        with torch.no_grad():\n",
    "            image = Variable(data_transforms(test_img).unsqueeze(0).cuda())\n",
    "            pre = self.seg_model.forward(image)\n",
    "            print(pre.shape)\n",
    "\n",
    "            if pre.size()[0] < 1024:\n",
    "                pre = F.upsample(pre, size=(1024, 2048), mode='bilinear')\n",
    "\n",
    "            pre = F.log_softmax(pre, dim=1)\n",
    "            pre = pre.data.cpu().numpy()\n",
    "\n",
    "            if is_flip:\n",
    "                tem = pre[0]\n",
    "                tem = tem.transpose(1, 2, 0)\n",
    "                tem = numpy.fliplr(tem)\n",
    "                tem = tem.transpose(2, 0, 1)\n",
    "                pre[0] = tem\n",
    "\n",
    "            return pre\n",
    "\n",
    "    @staticmethod\n",
    "    def __fushion_avg(pre):\n",
    "        pre_final = 0\n",
    "        for pre_scaled in pre:\n",
    "            pre_final = pre_final + pre_scaled\n",
    "        pre_final = pre_final / len(pre)\n",
    "        return pre_final\n",
    "\n",
    "    @staticmethod\n",
    "    def __load_weight(seg_model, model_path, is_local=True):\n",
    "        print(\"loading pre-trained weight\")\n",
    "        weight = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "        if is_local:\n",
    "            seg_model.load_state_dict(weight)\n",
    "        else:\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in weight.items():\n",
    "                name = k[7:]  # remove `module.`\n",
    "                new_state_dict[name] = v\n",
    "            seg_model.load_state_dict(new_state_dict)\n",
    "        print(\"loading complete\")\n",
    "\n",
    "    @staticmethod\n",
    "    def pre_to_img(pre):\n",
    "        result = pre.argmax(axis=1)[0]\n",
    "        row, col = result.shape\n",
    "        dst = numpy.zeros((row, col, 3), dtype=numpy.uint8)\n",
    "        for i in range(N_CLASS):\n",
    "            dst[result == i] = COLOR_MAP[i]\n",
    "        dst = numpy.array(dst, dtype=numpy.uint8)\n",
    "        dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "        return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119547037146038801333356\n"
     ]
    }
   ],
   "source": [
    "import pickle as pickle\n",
    "\n",
    "model_path = './weights/denseASPP161.pkl'\n",
    "\n",
    "fr = open(model_path,'rb')    #open的参数是pkl文件的路径\n",
    "inf = pickle.load(fr)       #读取pkl文件的内容\n",
    "print(inf)\n",
    "fr.close()                       #关闭文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseASPP161 ./weights/denseASPP161.pkl\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "model_name = 'DenseASPP161'\n",
    "model_path = './weights/denseASPP161.pkl'\n",
    "\n",
    "infer = Inference(model_name, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aachen_000000_000019_leftImg8bit.png\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "./results/data/aachen_000000_000019_leftImg8bit.png\n",
      "微信截图_20190426111814.png\n",
      "torch.Size([1, 19, 584, 864])\n",
      "./results/data/微信截图_20190426111814.png\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: './data/data.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f0f5db1364e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multiscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multiscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ad9a172c7d12>\u001b[0m in \u001b[0;36mfolder_inference\u001b[0;34m(self, img_dir, is_multiscale)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAVE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mread_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: './data/data.zip'"
     ]
    }
   ],
   "source": [
    "img_dir = './data'\n",
    "infer.folder_inference(img_dir, is_multiscale=False)\n",
    "infer.folder_inference(img_dir, is_multiscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "\n",
    "def train(epoch, infer, lossFunction, optimizer, device, trainloader):\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    infer.seg_model.train()     # enter train mode\n",
    "    train_loss = 0    # accumulate every batch loss in a epoch\n",
    "    correct = 0       # count when model' prediction is correct i train set\n",
    "    total = 0         # total number of prediction in train set\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device) # load data to gpu device\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        optimizer.zero_grad()            # clear gradients of all optimized torch.Tensors'\n",
    "        pre = infer.seg_model.forward(inputs)\n",
    "        print(pre.shape)\n",
    "\n",
    "        if pre.size()[0] < 1024:\n",
    "            pre = F.upsample(pre, size=(1024, 2048), mode='bilinear')\n",
    "\n",
    "        pre = F.log_softmax(pre, dim=1)\n",
    "        pre = pre.data.cpu().numpy()\n",
    "\n",
    "        outputs = Inference.pre_to_img(pre)          # forward propagation return the value of softmax function\n",
    "        print(inputs.shape,outputs.shape,targets.shape)\n",
    "        loss = lossFunction(outputs, targets) #compute loss\n",
    "        loss.backward()                  # compute gradient of loss over parameters \n",
    "        optimizer.step()                 # update parameters with gradient descent \n",
    "\n",
    "        train_loss += loss.item()        # accumulate every batch loss in a epoch\n",
    "        _, predicted = outputs.max(1)    # make prediction according to the outputs\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item() # count how many predictions is correct\n",
    "        \n",
    "        if (batch_idx+1) % 100 == 0:\n",
    "            # print loss and acc\n",
    "            print( 'Train loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
    "                % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    print( 'Train loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
    "                % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    \n",
    "def test(model, lossFunction, optimizer, device, testloader):\n",
    "    \"\"\"\n",
    "    test model's prediction performance on loader.  \n",
    "    When thid function is called, model is evaluated.\n",
    "    Args:\n",
    "        loader: data for evaluation\n",
    "        model: prediction model\n",
    "        loss_fn: loss function to judge the distance between target and outputs\n",
    "    output:\n",
    "        total_loss\n",
    "        accuracy\n",
    "    \"\"\"\n",
    "    global best_acc\n",
    "    model.eval() #enter test mode\n",
    "    test_loss = 0 # accumulate every batch loss in a epoch\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = lossFunction(outputs, targets) #compute loss\n",
    "\n",
    "            test_loss += loss.item() # accumulate every batch loss in a epoch\n",
    "            _, predicted = outputs.max(1) # make prediction according to the outputs\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item() # count how many predictions is correct\n",
    "        # print loss and acc\n",
    "        print('Test Loss: %.3f  | Test Acc: %.3f%% (%d/%d)'\n",
    "            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "        \n",
    "def data_loader():\n",
    "    # define method of preprocessing data for evaluating\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize a tensor image with mean and standard variance\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize a tensor image with mean and standard variance\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    \n",
    "    # prepare dataset by ImageFolder, data should be classified by directory\n",
    "    trainset = torchvision.datasets.ImageFolder(root='./mnist/train', transform=transform_train)\n",
    "\n",
    "    testset = torchvision.datasets.ImageFolder(root='./mnist/test', transform=transform_test)\n",
    "\n",
    "    # Data loader. \n",
    "\n",
    "    # Combines a dataset and a sampler, \n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "    return trainloader, testloader\n",
    "\n",
    "def run(infer, num_epochs):\n",
    "    \n",
    "    # load model into GPU device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    infer.seg_model.to(device)\n",
    "    \n",
    "    \n",
    "    # define the loss function and optimizer\n",
    "\n",
    "    lossFunction = nn.MSELoss()\n",
    "    lr = 0.01\n",
    "    optimizer = optim.SGD(infer.seg_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    trainloader, testloader = data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        train(epoch, infer, lossFunction, optimizer, device, trainloader)\n",
    "        test(model, lossFunction, optimizer, device, testloader)\n",
    "        if (epoch + 1) % 50 == 0 :\n",
    "            lr = lr / 10\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "torch.Size([64, 19, 32, 32])\n",
      "torch.Size([64, 3, 32, 32]) (32, 32, 3) torch.Size([64])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-55eecb0f8641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-985d88804d8e>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(infer, num_epochs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-985d88804d8e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, infer, lossFunction, optimizer, device, trainloader)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# forward propagation return the value of softmax function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# compute gradient of loss over parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# update parameters with gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "run(infer,num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
