{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image \n",
    "\n",
    "def read_labeled_image_list(data_dir, data_list):\n",
    "    f = open(data_list, 'r')\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "    for line in f:\n",
    "        try:\n",
    "            image, mask = line[:-1].split(' ')\n",
    "        except ValueError: # Adhoc for test.\n",
    "            image = mask = line.strip(\"\\n\")\n",
    "\n",
    "        image = os.path.join(data_dir, image)\n",
    "        mask = os.path.join(data_dir, mask)\n",
    "        mask = mask.strip()\n",
    "        \n",
    "#         if not torch.gfile.Exists(image):\n",
    "#             raise ValueError('Failed to find file: ' + image)\n",
    "\n",
    "#         if not tf.gfile.Exists(mask):\n",
    "#             raise ValueError('Failed to find file: ' + mask)\n",
    "\n",
    "        images.append(image)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "data_list = 'data/list/cityscapes_train_list.txt'\n",
    "data_list = 'data/list/test_list.txt'\n",
    "dataset = read_labeled_image_list(data_dir, data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['data/leftImg8bit/train/aachen/aachen_000000_000019_leftImg8bit.png'], ['data/gtFine/train/aachen/aachen_000000_000019_gtFine_labelTrainIds.png'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "class CustomDatasetFromImages(Dataset):\n",
    "    def __init__(self, datapath, listpath, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): csv 文件路径\n",
    "            img_path (string): 图像文件所在路径\n",
    "            transform: transform 操作\n",
    "        \"\"\"\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # 文件第一列包含图像文件的名称\n",
    "        self.image_arr, self.label_arr = read_labeled_image_list(data_dir, data_list)\n",
    "\n",
    "        # 计算 length\n",
    "        self.data_len = len(self.image_arr)\n",
    "        \n",
    "        self.transforms = transform\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        # 从 pandas df 中得到文件名\n",
    "        single_image_name = self.image_arr[index]\n",
    "        single_label_name = self.label_arr[index]\n",
    "        # 读取图像文件\n",
    "        img_as_img = Image.open(single_image_name)\n",
    "        \n",
    "        label_as_img = Image.open(single_label_name)\n",
    "\n",
    "        # 把图像转换成 tensor\n",
    "        img_as_tensor = self.to_tensor(img_as_img)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img_as_tensor = self.transforms(img_as_img)\n",
    " \n",
    "        # 得到图像的 label\n",
    "        single_image_label = self.to_tensor(label_as_img)\n",
    " \n",
    "        return (img_as_tensor, single_image_label)\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "dataset = CustomDatasetFromImages(data_dir, data_list, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_dataset_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                                    batch_size=10,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import torch.nn as nn\n",
    "\n",
    "# lossFunction = nn.MSELoss()\n",
    "# for images, labels in mn_dataset_loader:\n",
    "#     new_img_PIL = transforms.ToPILImage()(labels[0]).convert('RGB')\n",
    "#     new_img_PIL.show() # 处理后的PIL图片\n",
    "#     print(images.shape, labels.shape)\n",
    "#     loss = lossFunction(images, labels)\n",
    "#     print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "\n",
    "SAVE_PATH = \"./results/\"\n",
    "\n",
    "\n",
    "IS_MULTISCALE = True\n",
    "N_CLASS = 19\n",
    "COLOR_MAP = [(128, 64, 128), (244, 35, 232), (70, 70, 70), (102, 102, 156), (190, 153, 153), (153, 153, 153),\n",
    "             (250, 170, 30), (220, 220, 0), (107, 142, 35), (152, 251, 152), (70, 130, 180), (220, 20, 60),\n",
    "             (255,  0,  0), (0, 0, 142), (0, 0, 70), (0, 60, 100), (0, 80, 100), (0, 0, 230), (119, 11, 32)]\n",
    "\n",
    "inf_scales = [0.5, 0.75, 1.0, 1.25, 1.5, 1.8]\n",
    "data_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.290101, 0.328081, 0.286964],\n",
    "                                                           [0.182954, 0.186566, 0.184475])])\n",
    "\n",
    "\n",
    "class Inference(object):\n",
    "\n",
    "    def __init__(self, model_name, model_path):\n",
    "        print(model_name,model_path)\n",
    "\n",
    "        self.seg_model = self.__init_model(model_name, model_path, is_local=False)\n",
    "\n",
    "    def __init_model(self, model_name, model_path, is_local=False):\n",
    "        if model_name == 'MobileNetDenseASPP':\n",
    "            from cfgs.MobileNetDenseASPP import Model_CFG\n",
    "            from models.MobileNetDenseASPP import DenseASPP\n",
    "        elif model_name == 'DenseASPP121':\n",
    "            from cfgs.DenseASPP121 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "        elif model_name == 'DenseASPP169':\n",
    "            from cfgs.DenseASPP169 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "        elif model_name == 'DenseASPP201':\n",
    "            from cfgs.DenseASPP201 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "        elif model_name == 'DenseASPP161':\n",
    "            from cfgs.DenseASPP161 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "        else:\n",
    "            from cfgs.DenseASPP161 import Model_CFG\n",
    "            from models.DenseASPP import DenseASPP\n",
    "\n",
    "        seg_model = DenseASPP(Model_CFG, n_class=N_CLASS, output_stride=8)\n",
    "        #self.__load_weight(seg_model, model_path, is_local=is_local)\n",
    "        seg_model.train()\n",
    "        seg_model = seg_model.cuda()\n",
    "\n",
    "        return seg_model\n",
    "\n",
    "    def folder_inference(self, img_dir, is_multiscale=True):\n",
    "        folders = sorted(os.listdir(img_dir))\n",
    "        for f in folders:\n",
    "            save_path = SAVE_PATH + f + \"/\"\n",
    "            read_path = os.path.join(img_dir, f)\n",
    "            names = sorted(os.listdir(read_path))\n",
    "            for n in names:\n",
    "                if not n.endswith(\".png\"):\n",
    "                    continue\n",
    "                print(n)\n",
    "                read_name = os.path.join(read_path, n)\n",
    "                img = Image.open(read_name)\n",
    "                if is_multiscale:\n",
    "                    pre = self.multiscale_inference(img)\n",
    "                else:\n",
    "                    pre = self.single_inference(img)\n",
    "                mask = self.pre_to_img(pre)\n",
    "                cv2.imwrite(save_path + n, mask)\n",
    "                print(save_path + n)\n",
    "                #cv2.imshow('DenseASPP', mask)\n",
    "                #cv2.waitKey(0)\n",
    "\n",
    "    def multiscale_inference(self, test_img):\n",
    "        h, w = test_img.size\n",
    "        pre = []\n",
    "        for scale in inf_scales:\n",
    "            img_scaled = test_img.resize((int(h * scale), int(w * scale)), Image.CUBIC)\n",
    "            pre_scaled = self.single_inference(img_scaled, is_flip=False)\n",
    "            pre.append(pre_scaled)\n",
    "\n",
    "            img_scaled = img_scaled.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            pre_scaled = self.single_inference(img_scaled, is_flip=True)\n",
    "            pre.append(pre_scaled)\n",
    "\n",
    "        pre_final = self.__fushion_avg(pre)\n",
    "\n",
    "        return pre_final\n",
    "\n",
    "    def single_inference(self, test_img, is_flip=False):\n",
    "        with torch.no_grad():\n",
    "            image = Variable(data_transforms(test_img).unsqueeze(0).cuda())\n",
    "            pre = self.seg_model.forward(image)\n",
    "            print(pre.shape)\n",
    "\n",
    "            if pre.size()[0] < 1024:\n",
    "                pre = F.upsample(pre, size=(1024, 2048), mode='bilinear')\n",
    "\n",
    "            pre = F.log_softmax(pre, dim=1)\n",
    "            pre = pre.data.cpu().numpy()\n",
    "\n",
    "            if is_flip:\n",
    "                tem = pre[0]\n",
    "                tem = tem.transpose(1, 2, 0)\n",
    "                tem = numpy.fliplr(tem)\n",
    "                tem = tem.transpose(2, 0, 1)\n",
    "                pre[0] = tem\n",
    "\n",
    "            return pre\n",
    "\n",
    "    @staticmethod\n",
    "    def __fushion_avg(pre):\n",
    "        pre_final = 0\n",
    "        for pre_scaled in pre:\n",
    "            pre_final = pre_final + pre_scaled\n",
    "        pre_final = pre_final / len(pre)\n",
    "        return pre_final\n",
    "\n",
    "    @staticmethod\n",
    "    def __load_weight(seg_model, model_path, is_local=True):\n",
    "        print(\"loading pre-trained weight\")\n",
    "        weight = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "        if is_local:\n",
    "            seg_model.load_state_dict(weight)\n",
    "        else:\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in weight.items():\n",
    "                name = k[7:]  # remove `module.`\n",
    "                new_state_dict[name] = v\n",
    "            seg_model.load_state_dict(new_state_dict)\n",
    "        print(\"loading complete\")\n",
    "\n",
    "    @staticmethod\n",
    "    def pre_to_img(pre):\n",
    "        result = pre.argmax(axis=1)[0]\n",
    "        row, col = result.shape\n",
    "        dst = numpy.zeros((row, col, 3), dtype=numpy.uint8)\n",
    "        for i in range(N_CLASS):\n",
    "            dst[result == i] = COLOR_MAP[i]\n",
    "        dst = numpy.array(dst, dtype=numpy.uint8)\n",
    "        dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "        return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119547037146038801333356\n"
     ]
    }
   ],
   "source": [
    "import pickle as pickle\n",
    "\n",
    "model_path = './weights/denseASPP161.pkl'\n",
    "\n",
    "fr = open(model_path,'rb')    #open的参数是pkl文件的路径\n",
    "inf = pickle.load(fr)       #读取pkl文件的内容\n",
    "print(inf)\n",
    "fr.close()                       #关闭文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseASPP161 ./weights/denseASPP161.pkl\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(1)\n",
    "model_name = 'DenseASPP161'\n",
    "model_path = './weights/denseASPP161.pkl'\n",
    "\n",
    "infer = Inference(model_name, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aachen_000000_000019_leftImg8bit.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19, 2048, 4096])\n",
      "./results/data/aachen_000000_000019_leftImg8bit.png\n",
      "微信截图_20190426111814.png\n",
      "torch.Size([1, 19, 1176, 1728])\n",
      "./results/data/微信截图_20190426111814.png\n",
      "aachen_000000_000019_leftImg8bit.png\n",
      "torch.Size([1, 19, 2048, 4096])\n",
      "./results/test/aachen_000000_000019_leftImg8bit.png\n",
      "berlin_000000_000019_leftImg8bit.png\n",
      "torch.Size([1, 19, 2048, 4096])\n",
      "./results/test/berlin_000000_000019_leftImg8bit.png\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'data/'\n",
    "infer.folder_inference(img_dir, is_multiscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "import pynvml\n",
    "\n",
    "\n",
    "def train(epoch, infer, lossFunction, optimizer, device, trainloader):\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    infer.seg_model.train()     # enter train mode\n",
    "    train_loss = 0    # accumulate every batch loss in a epoch\n",
    "    correct = 0       # count when model' prediction is correct i train set\n",
    "    total = 0         # total number of prediction in train set\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device) # load data to gpu device\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        pre = infer.seg_model(inputs)\n",
    "        \n",
    "        for i in range(19):\n",
    "            print(i)\n",
    "            print(pre[0][i][1][1])\n",
    "\n",
    "        if pre.size()[0] < 1024:\n",
    "            pre = F.upsample(pre, size=(1024, 2048), mode='bilinear')\n",
    "\n",
    "        pre = F.log_softmax(pre, dim=1)\n",
    "        print(pre.shape)\n",
    "\n",
    "        outputs,b = pre.max(dim=1)\n",
    "        print(outputs[0][1][1])\n",
    "        \n",
    "        outputs = outputs.float()\n",
    "        \n",
    "        print(outputs[0][1][1])\n",
    "        \n",
    "        outputs = outputs.view([1, 1, 1024, 2048])\n",
    "        loss = lossFunction(outputs, targets) #compute loss\n",
    "        optimizer.zero_grad()            # clear gradients of all optimized torch.Tensors'\n",
    "\n",
    "        loss.backward()                  # compute gradient of loss over parameters \n",
    "        optimizer.step()                 # update parameters with gradient descent \n",
    "\n",
    "        train_loss += loss.item()        # accumulate every batch loss in a epoch\n",
    "        _, predicted = outputs.max(1)    # make prediction according to the outputs\n",
    "        total += 1024*2048\n",
    "        correct += outputs.eq(targets).sum().item() # count how many predictions is correct\n",
    "        \n",
    "        # print loss and acc\n",
    "        print( 'Train loss: %.3f | Train Acc: %.3f%% (%d/%d)' \n",
    "              % (train_loss, 100.*correct/total, correct, total))\n",
    "    print( 'Train loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
    "                % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    \n",
    "def test(model, lossFunction, optimizer, device, testloader):\n",
    "    \"\"\"\n",
    "    test model's prediction performance on loader.  \n",
    "    When thid function is called, model is evaluated.\n",
    "    Args:\n",
    "        loader: data for evaluation\n",
    "        model: prediction model\n",
    "        loss_fn: loss function to judge the distance between target and outputs\n",
    "    output:\n",
    "        total_loss\n",
    "        accuracy\n",
    "    \"\"\"\n",
    "    global best_acc\n",
    "    model.eval() #enter test mode\n",
    "    test_loss = 0 # accumulate every batch loss in a epoch\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = lossFunction(outputs, targets) #compute loss\n",
    "\n",
    "            test_loss += loss.item() # accumulate every batch loss in a epoch\n",
    "            _, predicted = outputs.max(1) # make prediction according to the outputs\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item() # count how many predictions is correct\n",
    "        # print loss and acc\n",
    "        print('Test Loss: %.3f  | Test Acc: %.3f%% (%d/%d)'\n",
    "            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "        \n",
    "def data_loader():\n",
    "    # define method of preprocessing data for evaluating\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize a tensor image with mean and standard variance\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        # Normalize a tensor image with mean and standard variance\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    \n",
    "    # prepare dataset by ImageFolder, data should be classified by directory\n",
    "    trainset = CustomDatasetFromImages(data_dir, data_list, transform=transform_train)\n",
    "\n",
    "    testset = CustomDatasetFromImages(data_dir, data_list, transform=transform_train)\n",
    "\n",
    "    # Data loader. \n",
    "\n",
    "    # Combines a dataset and a sampler, \n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "    return trainloader, testloader\n",
    "\n",
    "def loss(inputs, labels):\n",
    "    b,pre = inputs.max(dim=1)\n",
    "    for i in range(len(labels[0][0])):\n",
    "        for j in range(len(labels[0][0][i])):\n",
    "            if(pre!= labes[i][j]):\n",
    "                return 0\n",
    "\n",
    "def run(infer, num_epochs):\n",
    "    \n",
    "    # load model into GPU device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    infer.seg_model.to(device)\n",
    "    \n",
    "    \n",
    "    # define the loss function and optimizer\n",
    "\n",
    "    lossFunction = torch.nn.MSELoss()\n",
    "    lr = 0.01\n",
    "    optimizer = optim.SGD(infer.seg_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    trainloader, testloader = data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        train(epoch, infer, lossFunction, optimizer, device, trainloader)\n",
    "#         test(model, lossFunction, optimizer, device, testloader)\n",
    "        if (epoch + 1) % 50 == 0 :\n",
    "            lr = lr / 10\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "0\n",
      "tensor(2.5842, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-1.4539, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(6.4100, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-9.1608, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-13.6119, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(17.4387, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-0.1214, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(-2.6798, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(5.5984, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(9.4844, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(9.1985, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(6.6059, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(5.7753, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(8.2086, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(9.2236, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(4.1755, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(-9.0859, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-12.4080, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-0.2113, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-0.0010, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-0.0010, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 3.488 | Train Acc: 0.000% (0/2097152)\n",
      "Train loss: 3.488 | Train Acc: 0.000% (0/2097152)\n",
      "\n",
      "Epoch: 1\n",
      "0\n",
      "tensor(6.3991, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-1.2220, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(10.1001, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-12.6839, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-9.7581, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(17.3370, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-1.2516, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(1.1063, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(6.5294, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(6.3353, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(9.7274, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-2.0347, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(0.4296, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(4.7027, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(-0.5609, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(10.5785, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(-11.1928, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-4.7665, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-5.0127, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-0.0024, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-0.0024, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 0.257 | Train Acc: 0.000% (0/2097152)\n",
      "Train loss: 0.257 | Train Acc: 0.000% (0/2097152)\n",
      "\n",
      "Epoch: 2\n",
      "0\n",
      "tensor(-0.2475, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(0.6618, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(9.0093, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-17.4032, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-7.9560, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(16.5278, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(0.3588, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(-2.4627, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(1.0983, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(9.1845, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(2.6167, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-5.6188, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(8.0979, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(11.3742, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(8.9849, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(-0.3482, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(3.4839, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-9.6354, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-7.4899, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-0.0077, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-0.0077, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 0.090 | Train Acc: 0.081% (1704/2097152)\n",
      "Train loss: 0.090 | Train Acc: 0.081% (1704/2097152)\n",
      "\n",
      "Epoch: 3\n",
      "0\n",
      "tensor(-7.6344, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-5.9471, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(9.5490, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-12.2458, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-13.0145, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(23.3072, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-7.3162, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(-7.1909, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(3.7363, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(9.0952, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(7.3315, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-7.0615, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(11.0236, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(10.6692, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(13.7849, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(2.9204, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(5.0141, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-6.4481, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-4.8059, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-8.2016e-05, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-8.2016e-05, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 0.078 | Train Acc: 32.531% (682220/2097152)\n",
      "Train loss: 0.078 | Train Acc: 32.531% (682220/2097152)\n",
      "\n",
      "Epoch: 4\n",
      "0\n",
      "tensor(-3.2432, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-5.4905, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(4.3692, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-14.6029, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-11.6535, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(29.6394, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-3.1159, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(-6.2591, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(5.0523, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(12.7427, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(9.2018, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-2.8580, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(7.6435, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(5.5064, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(14.1982, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(2.7715, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(17.8602, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-6.6774, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-7.3540, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-7.6294e-06, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-7.6294e-06, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 0.074 | Train Acc: 38.846% (814651/2097152)\n",
      "Train loss: 0.074 | Train Acc: 38.846% (814651/2097152)\n",
      "\n",
      "Epoch: 5\n",
      "0\n",
      "tensor(-2.6843, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-7.5892, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(1.7219, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-17.1102, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-10.8870, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(28.1221, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-10.0311, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(-4.3914, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(8.3320, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(13.3110, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(7.2239, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-1.2037, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(7.2112, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(0.4615, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(8.3281, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(1.6262, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(16.6415, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-8.2350, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-12.9973, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-1.1444e-05, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-1.1444e-05, device='cuda:1', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.071 | Train Acc: 39.198% (822048/2097152)\n",
      "Train loss: 0.071 | Train Acc: 39.198% (822048/2097152)\n",
      "\n",
      "Epoch: 6\n",
      "0\n",
      "tensor(-6.4040, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-4.4846, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(1.7443, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-14.5125, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-12.2500, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(36.3393, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-5.4464, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(-10.7749, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(7.7874, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(13.9188, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(7.7421, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-3.2051, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(7.4039, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(12.2990, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(9.8223, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(-9.6081, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(24.8796, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-9.8227, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-9.0233, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-1.1444e-05, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-1.1444e-05, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 0.069 | Train Acc: 39.358% (825391/2097152)\n",
      "Train loss: 0.069 | Train Acc: 39.358% (825391/2097152)\n",
      "\n",
      "Epoch: 7\n",
      "0\n",
      "tensor(-10.2131, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-3.5488, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(0.1664, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-17.0870, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-3.3422, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(30.8145, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-5.4436, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(-9.4998, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(8.0111, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(12.6483, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(-3.2051, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-10.0298, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(2.0030, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(11.0035, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(12.9256, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(-1.8106, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(33.2174, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-13.7346, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-9.1374, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-0.0866, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-0.0866, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 0.067 | Train Acc: 39.476% (827879/2097152)\n",
      "Train loss: 0.067 | Train Acc: 39.476% (827879/2097152)\n",
      "\n",
      "Epoch: 8\n",
      "0\n",
      "tensor(-7.5090, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-7.9333, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(-0.4334, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-11.5076, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-10.6123, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(40.0643, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-8.1041, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(-6.1416, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(9.4443, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(15.8454, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(4.7400, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-8.1534, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(9.6934, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(9.0794, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(18.0872, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(-2.1491, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(28.3987, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-9.5942, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-9.5921, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-7.6294e-06, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-7.6294e-06, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 0.068 | Train Acc: 39.496% (828285/2097152)\n",
      "Train loss: 0.068 | Train Acc: 39.496% (828285/2097152)\n",
      "\n",
      "Epoch: 9\n",
      "0\n",
      "tensor(-6.7263, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "1\n",
      "tensor(-11.1099, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "2\n",
      "tensor(6.6338, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "3\n",
      "tensor(-13.2862, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "4\n",
      "tensor(-15.7810, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "5\n",
      "tensor(30.8436, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "6\n",
      "tensor(-11.8656, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "7\n",
      "tensor(0.4528, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "8\n",
      "tensor(1.0482, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "9\n",
      "tensor(9.8104, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "10\n",
      "tensor(6.5224, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "11\n",
      "tensor(-0.3239, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "12\n",
      "tensor(6.8050, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "13\n",
      "tensor(6.0444, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "14\n",
      "tensor(18.2595, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "15\n",
      "tensor(-7.7411, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "16\n",
      "tensor(27.3960, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "17\n",
      "tensor(-12.8145, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "18\n",
      "tensor(-9.3908, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 19, 1024, 2048])\n",
      "tensor(-0.0313, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "tensor(-0.0313, device='cuda:1', grad_fn=<SelectBackward>)\n",
      "Train loss: 0.067 | Train Acc: 39.521% (828823/2097152)\n",
      "Train loss: 0.067 | Train Acc: 39.521% (828823/2097152)\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2ac595c9c9ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-1f3bb258fb87>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(infer, num_epochs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;31m#         test(model, lossFunction, optimizer, device, testloader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1f3bb258fb87>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, infer, lossFunction, optimizer, device, trainloader)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m       \u001b[0;31m# count when model' prediction is correct i train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m         \u001b[0;31m# total number of prediction in train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load data to gpu device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3e6afe6a8d3c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# 把图像转换成 tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mimg_as_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;31m# PIL image mode: L, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run(infer,num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
